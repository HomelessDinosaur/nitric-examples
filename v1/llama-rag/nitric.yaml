name: llama-rag
services:
  - match: services/chat.py
    runtime: python
    start: uv run $SERVICE_PATH
  - match: services/subscriber.py
    runtime: model
    start: uv run $SERVICE_PATH

runtimes:
  python:
    dockerfile: ./python.dockerfile
  model:
    dockerfile: ./model.dockerfile
